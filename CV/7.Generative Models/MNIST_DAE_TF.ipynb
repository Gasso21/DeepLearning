{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a935e6d3",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a0685ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313f8daf",
   "metadata": {},
   "source": [
    "## Denoising AutoEncoder\n",
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2b37e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "544c114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "image_size = x_train.shape[1:]\n",
    "x_train = np.reshape(x_train, [-1, x_train.shape[1], x_train.shape[2], 1])\n",
    "x_test = np.reshape(x_test, [-1, x_test.shape[1], x_test.shape[2], 1])\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "\n",
    "# 노이즈 추가\n",
    "noise = np.random.normal(loc=0.5, scale=0.5, size=x_train.shape)\n",
    "x_train_noisy = x_train + noise\n",
    "noise = np.random.normal(loc=0.5, scale=0.5, size=x_test.shape)\n",
    "x_test_noisy = x_test + noise\n",
    "\n",
    "# 0. ~ 1. 사이로 제한\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93caef9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b88a0b",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6de515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, Conv2DTranspose, Flatten, Dense, Reshape\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41dcfd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1:]\n",
    "batch_size = 32\n",
    "kernel_size = 3\n",
    "latent_dim = 16\n",
    "layer_filters = [32, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "641c16bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(inputs, layer_filters, latent_dim):\n",
    "    x = inputs\n",
    "    for filters in layer_filters:\n",
    "        x = Conv2D(filters=filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   activation='relu',\n",
    "                   strides=2,\n",
    "                   padding='same'\n",
    "                  )(x)\n",
    "    shape = K.int_shape(x) \n",
    "    x = Flatten()(x)\n",
    "    latent = Dense(latent_dim, name='latent_vector')(x)\n",
    "    \n",
    "    return latent, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16f3069f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " latent_vector (Dense)       (None, 16)                50192     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,008\n",
      "Trainable params: 69,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=input_shape, name='encoder_input')\n",
    "latent, shape = encoder(inputs, layer_filters, latent_dim)\n",
    "encoder = keras.Model(inputs=inputs, outputs=latent, name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4f7b2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(latent_inputs, shape, layer_filters, kernel_size):\n",
    "    x = Dense(shape[1]*shape[2]*shape[3])(latent_inputs) # Flatten\n",
    "    x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "    \n",
    "    for filters in layer_filters[::-1]:\n",
    "        x = Conv2DTranspose(filters=filters,\n",
    "                            kernel_size=kernel_size,\n",
    "                            activation='relu',\n",
    "                            strides=2,\n",
    "                            padding='same'\n",
    "                           )(x)\n",
    "    outputs = Conv2DTranspose(filters=1,\n",
    "                              kernel_size=kernel_size,\n",
    "                              activation='sigmoid',\n",
    "                              padding='same',\n",
    "                              name='decoder_output'\n",
    "                             )(x)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc7b497f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decoder_input (InputLayer)  [(None, 16)]              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3136)              53312     \n",
      "                                                                 \n",
      " reshape_3 (Reshape)         (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_6 (Conv2DT  (None, 14, 14, 64)       36928     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_7 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " decoder_output (Conv2DTrans  (None, 28, 28, 1)        289       \n",
      " pose)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,993\n",
      "Trainable params: 108,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,), name='decoder_input')\n",
    "outputs = decoder(latent_inputs, shape, layer_filters, kernel_size)\n",
    "decoder = keras.Model(inputs=latent_inputs, outputs=outputs, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f83d4ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = keras.Model(inputs, decoder(encoder(inputs)), name='autoencoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b1f7ff15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 16)                69008     \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 28, 28, 1)         108993    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 178,001\n",
      "Trainable params: 178,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(loss='mse',\n",
    "                    optimizer='adam'\n",
    "                   )\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "81efb0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-04 16:17:50.036883: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-02-04 16:17:50.277335: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1873/1875 [============================>.] - ETA: 0s - loss: 0.0349"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-04 16:18:05.842551: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.0349 - val_loss: 0.0202\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0193 - val_loss: 0.0181\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0177 - val_loss: 0.0172\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0169 - val_loss: 0.0166\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0164 - val_loss: 0.0163\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0160 - val_loss: 0.0161\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0157 - val_loss: 0.0160\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0155 - val_loss: 0.0158\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0153 - val_loss: 0.0157\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0152 - val_loss: 0.0157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d42bf250>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                epochs=10,\n",
    "                batch_size=batch_size\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b238db9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
